# Implement Ollama Provider

- **Status:** READY
- **Points:** 3
- **Story ID:** 023
- **Type:** Feature

## Description
Implement the `OllamaProvider` class to communicate with a local Ollama instance.

## User Story
**As a** User,
**I want** to use local models,
**So that** I don't incur API costs.

## Acceptance Criteria
- [ ] Connects to Ollama API URL.
- [ ] Implements `chat` with streaming support.
- [ ] Implements `listModels`.

## Testing
1. Mock Ollama API response.
2. Verify chat completion parsing.

## Review Log
